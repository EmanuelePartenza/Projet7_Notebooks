{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6f7bf5",
   "metadata": {},
   "source": [
    "## TABLE DES MATIERES\n",
    "\n",
    "### 0.1 Import Librairies\n",
    "### 0.2 Read_csv\n",
    "### 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f9a96",
   "metadata": {},
   "source": [
    "## 0. Import Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3915d5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "tic = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import os\n",
    "import glob\n",
    "import shap\n",
    "\n",
    "from contextlib import contextmanager\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, roc_curve\n",
    "from sklearn.metrics import make_scorer, fbeta_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, space_eval\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "separator_line = '\\n\\n'+'\\033[1m_\\033[0m'*100+'\\n'+'\\033[1m_\\033[0m'*100+'\\n\\n'\n",
    "pd.set_option('display.max_rows', 4000)\n",
    "pd.set_option('display.max_columns', 4000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed854948",
   "metadata": {},
   "source": [
    "### 0.2 Read_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1ab05",
   "metadata": {},
   "source": [
    "##### The column description csv file describes the Target field as follows:\n",
    "\n",
    "1 - client with payment difficulties: he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample\n",
    "\n",
    "0 - all other cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab84dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "# df = pd.read_csv('./output_datasets/DataFrame.csv')\n",
    "\n",
    "# Test\n",
    "X_test = pd.read_csv('./output_datasets/X_test.csv')\n",
    "y_test = pd.read_csv('./output_datasets/y_test.csv')\n",
    "\n",
    "X_test = X_test.set_index('SK_ID_CURR')\n",
    "y_test = y_test.set_index('SK_ID_CURR')\n",
    "\n",
    "# Train\n",
    "X_train = pd.read_csv('./output_datasets/X_train.csv')\n",
    "y_train = pd.read_csv('./output_datasets/y_train.csv')\n",
    "\n",
    "features = X_train.columns\n",
    "# X_train = X_train.to_numpy()\n",
    "y_train = y_train['TARGET'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e2e13a",
   "metadata": {},
   "source": [
    "### 0.3 Display's functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668b72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf_matrix_roc_auc(model, y_true, y_pred, y_pred_proba, features_importance, features=features, importance_range=30 ):\n",
    "    '''This function will make a pretty plot of \n",
    "  an sklearn Confusion Matrix using a Seaborn heatmap visualization + ROC Curve.'''\n",
    "    fig = plt.figure(figsize=(20,15))\n",
    "  \n",
    "    plt.subplot(221)\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    cf_matrix_normalize_true = confusion_matrix(y_true, y_pred, normalize='true')\n",
    "    cf_matrix_normalize_all = confusion_matrix(y_true, y_pred, normalize='all')\n",
    "    \n",
    "    group_names = ['True Pos', 'False Neg', 'False Pos', 'True Neg']\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "    group_normalize_true = [\"{0:.2%}\".format(value) for value in cf_matrix_normalize_true.flatten()]\n",
    "    group_normalize_all = [\"{0:.2%}\".format(value) for value in cf_matrix_normalize_all.flatten()]\n",
    "  \n",
    "    labels = [f\"{v1}\\ncount : {v2}\\nnormalize over true : {v3}\\nnormalize over all : {v4}\" for v1, v2, v3, v4 in zip(group_names,group_counts,group_normalize_true,group_normalize_all)]\n",
    "    labels = np.asarray(labels).reshape(2,2)\n",
    "    sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap='Blues')\n",
    "\n",
    "    plt.subplot(222)\n",
    "    fpr,tpr,_ = roc_curve(y_true, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, color='orange', linewidth=5)#, label='AUC = %0.4f' %roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "\n",
    "    if features_importance : \n",
    "        plt.subplot(212)\n",
    "        indices = np.argsort(model.feature_importances_)[::-1]\n",
    "        features = features[:importance_range]\n",
    "        \n",
    "        sns.barplot(x=features, y=model.feature_importances_[indices[range(importance_range)]], color=(\"orange\"))\n",
    "        plt.xlabel('Features importance')\n",
    "        plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    plt.close('all')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b9fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_scores(model_dict, fist_bar_position = 1, \n",
    "               first_bar_label='cross validation roc score', \n",
    "               second_bar_position = 2, \n",
    "               second_bar_label='true & predict roc score'):\n",
    "    \n",
    "    ziped_dict = list(zip(*model_dict.values()))\n",
    "    ziped_dict[fist_bar_position]\n",
    "    ziped_dict[second_bar_position]\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = (3,3)\n",
    "    plt.figure()\n",
    "    plt.title('Scores', fontsize=20)\n",
    "    plt.ylabel('Model',fontsize=10)\n",
    "    plt.xlabel('score',fontsize=10)\n",
    "    \n",
    "    X_axis = np.arange(len(model_dict))\n",
    "    width=1/5\n",
    "    \n",
    "    plt.barh(X_axis+width, ziped_dict[fist_bar_position], width*2, label=first_bar_label)\n",
    "    plt.barh(X_axis-width, ziped_dict[second_bar_position], width*2, label=second_bar_label)\n",
    "    \n",
    "    plt.yticks(X_axis, model_dict.keys())\n",
    "    plt.xlim([0,1])\n",
    "    plt.tick_params( length =5, labelsize=10)\n",
    "    plt.grid(linewidth=0.5, color = 'black')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.margins(0.001)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331930ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\\n\\n\".format(title, time.time() - t0)+\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83217008",
   "metadata": {},
   "source": [
    "### 1.1 Classification's models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808719a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_read_model(create=False, version=1, score='roc_auc',cv=5, reg_model_name=None, Estimator=None, param_grid=None):\n",
    "    if create:\n",
    "        time_start=time.time()\n",
    "        with mlflow.start_run(run_name=reg_model_name) as run:\n",
    "            \n",
    "            grid = GridSearchCV(eval(Estimator),\n",
    "                                param_grid=param_grid,\n",
    "                                scoring=score,\n",
    "                                cv=cv,\n",
    "                                verbose=10)\n",
    "            \n",
    "            grid.fit(X_train, y_train)\n",
    "            mlflow.log_params(param_grid)\n",
    "            mlflow.sklearn.log_model(sk_model = grid,\n",
    "                                    artifact_path=\"classifier\",\n",
    "                                    registered_model_name=reg_model_name)\n",
    "            time_end=time.time()\n",
    "            model = grid\n",
    "            time = round((time_end-time_start)/60,2)\n",
    "            np.save(f'./Execution_model_time/{reg_model_name}_{version}.npy', np.array(time))\n",
    "    else :\n",
    "        model_uri = f\"models:/{reg_model_name}/{version}\"\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "#         time = np.load(f'./Execution_model_time/{reg_model_name}_{version}.npy')\n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    #OUTPUT\n",
    "    print('\\n\\n'+reg_model_name+' : ')\n",
    "#     print(f\"\\n\\texecution time : {time}\")\n",
    "    print(f\"\\n\\tbest_score_ : {round(model.best_score_,3)}\")\n",
    "    print(f\"\\n\\troc_auc_score : {round(roc_auc_score(y_pred, y_test),3)}\")\n",
    "    cf_matrix_roc_auc(model, y_test, y_pred, y_pred_proba[:,1], features_importance=False)\n",
    "    print(separator_line)\n",
    "    \n",
    "    return model, model.best_score_, roc_auc_score(y_pred, y_test), fbeta_score(y_pred, y_test, beta=50)#, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict ={}\n",
    "model_dict[\"DummyClassifier\"] = create_or_read_model(create=False, \n",
    "                                    version=1, \n",
    "                                    score='roc_auc',\n",
    "                                    cv=5, \n",
    "                                    reg_model_name=\"DummyClassifier\", \n",
    "                                    Estimator=\"DummyClassifier()\", \n",
    "                                    param_grid={'strategy' : ['stratified', 'uniform']})\n",
    "\n",
    "model_dict[\"LogisticRegression\"] = create_or_read_model(create=False, \n",
    "                                    version=1, \n",
    "                                    score='roc_auc',\n",
    "                                    cv=5, \n",
    "                                    reg_model_name=\"LogisticRegression\", \n",
    "                                    Estimator=\"LogisticRegression()\", \n",
    "                                    param_grid = {'penalty' : ['l2'],\n",
    "                                                  'max_iter' : [1000]}\n",
    "                                    )\n",
    "model_dict[\"RandomForestClassifier\"] = create_or_read_model(create=False, \n",
    "                                    version=1, \n",
    "                                    score='roc_auc',\n",
    "                                    cv=5, \n",
    "                                    reg_model_name=\"RandomForestClassifier\", \n",
    "                                    Estimator=\"RandomForestClassifier()\", \n",
    "                                    param_grid = {'criterion' : ['gini', 'entropy'],\n",
    "                                                  'max_depth' : [200]}\n",
    "                                    )\n",
    "model_dict[\"LGBMClassifier\"] = create_or_read_model(create=False, \n",
    "                                    version=1, \n",
    "                                    score='roc_auc',\n",
    "                                    cv=5, \n",
    "                                    reg_model_name=\"LGBMClassifier\", \n",
    "                                    Estimator=\"LGBMClassifier()\", \n",
    "                                    param_grid = {'n_estimators' : [1000],\n",
    "                                      'learning_rate' : [0.02],\n",
    "                                      'max_depth' : [8]}\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_scores(model_dict, fist_bar_position = 1, \n",
    "           first_bar_label='cross validation roc score', \n",
    "           second_bar_position = 2, \n",
    "           second_bar_label='true & predict roc score')\n",
    "\n",
    "# plt_scores(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0721dd",
   "metadata": {},
   "source": [
    "Specificity score:\n",
    "https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c61466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Specificity\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "    tp, fn, fp, tn = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return tn/(tn + fp)\n",
    "\n",
    "specificity_score = make_scorer(specificity)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def custom_metric(y_true,y_pred):\n",
    "    tp, fn, fp, tn = confusion_matrix(y_true, y_pred).ravel()\n",
    "#     return (1 - fp/(fp+tn))\n",
    "    return fn+fp*10\n",
    "\n",
    "custom_score = make_scorer(custom_metric, greater_is_better=False)\n",
    "\n",
    "\n",
    "# pos_label\n",
    "\n",
    "fbeta_500_scorer = make_scorer(fbeta_score, beta=50, pos_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d97b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, learning_curve, cross_validate\n",
    "\n",
    "device = 'gpu'\n",
    "n_estimators = 250\n",
    "n_KFolds = 3\n",
    "max_evals = 30\n",
    "\n",
    "def objective(params):\n",
    "    params = {\n",
    "        'max_depth': int(params['max_depth']),\n",
    "        'reg_alpha' : int(params['reg_alpha']),\n",
    "        'min_child_weight' : int(params['min_child_weight']),\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree'],\n",
    "        'reg_lambda': params['reg_lambda'],\n",
    "        'device' : device,\n",
    "        'n_estimators': n_estimators,\n",
    "        }\n",
    "    model= LGBMClassifier(**params)\n",
    "    cv = StratifiedKFold(n_KFolds)\n",
    "    y_pred = cross_val_predict(model, X_train, y_train, method='predict', cv=cv)\n",
    "    score = specificity(y_train, y_pred)\n",
    "    return {'loss': (1 - score), 'status': STATUS_OK }\n",
    "\n",
    "def LGBM_hyperopt(run_name):\n",
    "    space = {\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.001, 0.03),\n",
    "        'max_depth': hp.quniform('max_depth', 10, 30, 10),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'subsample': hp.uniform('subsample', 0.60, 0.95),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.60, 0.95),\n",
    "        'reg_lambda': hp.uniform('reg_lambda', 1, 20),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        }\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective, space=space, max_evals=max_evals, algo=tpe.suggest)\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        lgbm = LGBMClassifier(\n",
    "            max_depth= int(best['max_depth']),\n",
    "            reg_alpha=int(best['reg_alpha']),\n",
    "            min_child_weight=int(best['min_child_weight']),\n",
    "            learning_rate= best['learning_rate'],\n",
    "            subsample= best['subsample'],\n",
    "            colsample_bytree= best['colsample_bytree'],\n",
    "            reg_lambda= best['reg_lambda'],\n",
    "            n_estimators=n_estimators,\n",
    "            device=device\n",
    "            )\n",
    "        lgbm.fit(X_train, y_train)\n",
    "        mlflow.log_params(best)\n",
    "        mlflow.sklearn.log_model(sk_model = lgbm,\n",
    "                                    artifact_path=\"classifier\",\n",
    "                                    registered_model_name=run_name)\n",
    "    return\n",
    "# LGBM_hyperopt(run_name='LGBM_Hyperopt_specificity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884df24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cd9b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"models:/LGBM_Hyperopt_specificity/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea99a2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "estimator.append(key)\n",
    "grid_best_score.append(loaded_model.best_score_)\n",
    "roc_score.append(roc_auc_score(y_pred, y_test))\n",
    "fbeta_500_score.append(fbeta_score(y_pred, y_test, beta=50))\n",
    "\n",
    "print(key+' : ')\n",
    "print(f\" roc_auc_score : {round(roc_auc_score(y_pred, y_test),3)}\")\n",
    "cf_matrix_roc_auc(model, y_test, y_pred, y_pred_proba[:,1], features_importance=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df93c75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def X_sample(create=False):\n",
    "    if create:\n",
    "        X_test_sample = X_test.sample(300)\n",
    "        X_test_sample.to_csv('./output_datasets/X_test_sample.csv')\n",
    "        X_test_sample.to_csv(r\"C:\\Users\\emanu\\Documents\\FastAPI\\X_test_sample.csv\", index=False)\n",
    "    X_test_sample = pd.read_csv('./output_datasets/X_test_sample.csv',index_col='SK_ID_CURR')\n",
    "    return X_test_sample\n",
    "\n",
    "def prediction_shap_model(X_test_sample, create=False, model_uri=\"models:/LGBM_Hyperopt_specificity/1\" ):\n",
    "    if create:\n",
    "        # load model\n",
    "        model = mlflow.sklearn.load_model(model_uri)\n",
    "        # predict\n",
    "        y_pred = model.predict(X_test_sample)\n",
    "        y_pred_proba = model.predict_proba(X_test_sample)\n",
    "        y_pred_proba = list(zip(*y_pred_proba))\n",
    "        id_list = X_test_sample.index.tolist()\n",
    "        # predict dataframe\n",
    "        prediction_df = pd.DataFrame()\n",
    "        prediction_df['id'] = id_list\n",
    "        prediction_df['y_pred'] = y_pred\n",
    "        prediction_df['y_proba_0'] = y_pred_proba[0]\n",
    "        prediction_df['y_proba_1'] = y_pred_proba[1]\n",
    "        # shap\n",
    "        with mlflow.start_run() as run:\n",
    "            mlflow.shap.log_explanation(model.predict, X_test_sample)\n",
    "        client = MlflowClient()\n",
    "        artifact_path = \"model_explanations_shap\"\n",
    "        artifacts = [x.path for x in client.list_artifacts(run.info.run_id, artifact_path)]\n",
    "        dst_path = client.download_artifacts(run.info.run_id, artifact_path)\n",
    "        base_values = np.load(os.path.join(dst_path, \"base_values.npy\"))\n",
    "        shap_values = np.load(os.path.join(dst_path, \"shap_values.npy\"))\n",
    "        \n",
    "        \n",
    "        # save results on Projet_7 folder\n",
    "        np.save(\"./output_datasets/model_explanations_shap/base_values.npy\",shap_values)\n",
    "        np.save(\"./output_datasets/model_explanations_shap/shap_values.npy\",shap_values)\n",
    "        prediction_df.to_csv('./output_datasets/prediction_X_test_sample_df.csv', index=False)\n",
    "        # save results on FastAPI folder\n",
    "        np.save(r\"C:\\Users\\emanu\\Documents\\FastAPI\\model_explanations_shap\\base_values.npy\",shap_values)\n",
    "        np.save(r\"C:\\Users\\emanu\\Documents\\FastAPI\\model_explanations_shap\\shap_values.npy\",shap_values)\n",
    "        prediction_df.to_csv(r\"C:\\Users\\emanu\\Documents\\FastAPI\\prediction_X_test_sample_df.csv\", index=False)\n",
    "    # read\n",
    "    base_values = np.load(\"./output_datasets/model_explanations_shap/base_values.npy\")\n",
    "    shap_values = np.load(\"./output_datasets/model_explanations_shap/shap_values.npy\")\n",
    "    prediction_df = pd.read_csv('./output_datasets/prediction_X_test_sample_df.csv', index_col='id')\n",
    "    return base_values, shap_values, prediction_df\n",
    "\n",
    "# run functions\n",
    "X_test_sample = X_sample(create=False)\n",
    "base_values, shap_values, prediction_df = prediction_shap_model(X_test_sample, create=False, model_uri=\"models:/LGBM_Hyperopt_specificity/1\")\n",
    "\n",
    "# SHOW\n",
    "print('X_test_sample')\n",
    "display(X_test_sample.head(5))\n",
    "print('base_values')\n",
    "print(base_values)\n",
    "print('shap_values')\n",
    "print(shap_values)\n",
    "print('prediction_df')\n",
    "display(prediction_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toc=time.time()\n",
    "print(f\"Notebook execution time : {round((toc-tic)/60,2)} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf61aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# model_pickle = pickle.load(open('model.pkl','rb'))\n",
    "# sk_id = 141817\n",
    "# y_pred = model_pickle.predict(X_test.loc[X_test.index == sk_id])[0]\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8895a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk for the API\n",
    "filename = r\"C:\\Users\\emanu\\Documents\\FastAPI\\final_model.sav\"\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# check if model is correcly loaded\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab162097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if model is correcly loaded\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ce0b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_0 = model.predict_proba(X_test)\n",
    "proba_0 = [i*100 for i in list(zip(*proba_0))[0]]\n",
    "all_proba = pd.DataFrame()\n",
    "all_proba['prob'] = proba_0\n",
    "all_proba.to_csv(r\"C:\\Users\\emanu\\Documents\\Dash_app\\all_proba.csv\", index=False)\n",
    "pd.read_csv(r\"C:\\Users\\emanu\\Documents\\Dash_app\\all_proba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 4\n",
    "time_start=time.time()\n",
    "reg_model_name = \"LogisticRegression_betascore\"\n",
    "\n",
    "Estimator = \"LogisticRegression()\"\n",
    "param_grid = {'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "              'max_iter' : [2000],\n",
    "              'solver':['lbfgs', 'liblinear', 'newton-cholesky']              \n",
    "             }\n",
    "with mlflow.start_run(run_name=reg_model_name) as run:\n",
    "    \n",
    "    grid = GridSearchCV(eval(Estimator),\n",
    "                        param_grid=param_grid,\n",
    "                        scoring=fbeta_500_scorer,\n",
    "                        cv=cv,\n",
    "                        verbose=10\n",
    "                       )\n",
    "    grid.fit(X_train, y_train)\n",
    "    mlflow.log_params(param_grid)\n",
    "    mlflow.sklearn.log_model(sk_model = grid,\n",
    "                            artifact_path=\"classifier\",\n",
    "                            registered_model_name=reg_model_name)\n",
    "    time_end=time.time()        \n",
    "    print(reg_model_name+\" execution time : {}min\".format(round((time_end-time_start)/60,2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "63ff03f735add663ddf30cd111bac5b70c8c31a98d364f6d11c008835134ea5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
